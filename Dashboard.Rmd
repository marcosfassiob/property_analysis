---
title: "Property Sale Value Analysis"
author: "Marcos Fassio Bazzi, Ariq Rashid"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    source_code: embed
    theme: yeti
---

```{r setup, include=FALSE}
library(flexdashboard)
library(knitr) # I recommend doing this here
library(olsrr)
library(leaps)
library(ggplot2)
library(faraway)
library(GGally)
library(tidyverse)
library(glmnet)
library(ISLR2)
library(splines)
library(caret)
library(FNN)
```

```{r}
##CHANGE THIS WORKING DIRECTORY--------------------
setwd("C:/Users/marco/Desktop/CMDA 4654/Projects/Project 1")
```

```{r}
df <- read.csv("data/property.csv", header=TRUE)
wake_cols <- c(10, 18:21, 24:29, 34, 43:46, 48, 50, 52, 53, 59, 61) # columns i want in cleaned data
useless_APA_cols <- c("Site In Natural State", "Developing Site") # rows i DONT want in cleaned data
useless_land_class_cols <- c("Part Exempt", "State Assessed", "Vacant Land", "Manufactured Home", 
                       "Manufactured Home Park")
useless_ownership_cols <- c("County, Parish, Province, Etc.", "Federal Government")

df_w <- df %>%
    dplyr::select(all_of(wake_cols)) %>%
    mutate_if(is.character, list(~na_if(.,""))) %>%
    filter(Land.Value != 0 & Building.Value != 0 & Land.Sale.Value > 0 & Total.Sale.Value > 0) %>%
    filter(!APA.Site.Description %in% useless_APA_cols) %>% 
    filter(!Land.Class %in% useless_land_class_cols) %>% 
    filter(!APA.Ownership.Description %in% useless_ownership_cols) %>%
    # only one instance found - essentially an exception
    drop_na()
```

Overview
=======================================================================

data summary {data-width=350}
-----------------------------------------------------------------------

### About our Data

Our data contains real estate data from portions of North Carolina's Wake County, Chatham County and Durham County. The dataset contains about 270,000 observations and 63 variables containing real estate data - including but not limited to houses, apartments and commercial property. After cleaning our data, the dataset only contains data from Wake County and contains about 64,000 observations and 22 variables. 

* Source: [data.gov](https://catalog.data.gov/dataset/real-estate-data) 
* Landing page: [townofcary.org](https://data.townofcary.org/explore/dataset/property/information) 
* Raw Data: [Google Drive](https://drive.google.com/file/d/15Gm2mkMeiIoca7K-YL8wG-0lwqsXrdJG/view?usp=sharing).

Our responsibilities are divided as follows:

* Ariq:
    - Natural Cubic Splines
    - k-Nearest Neighbors Classification
    - Ridge Regression
* Marcos:
    - Multiple Linear Regression
    - Naive Bayes Classification
    - Logistic Regression

Table Summary {data-width=650}
-----------------------------------------------------------------------

### Table Summary

|            **Name**           |                              **Description**                              |
|:-----------------------------:|:-------------------------------------------------------------------------:|
|       Calculated.Acreage      |                   Calculated area from property in acres                  |
|           Land.Class          |                      Land classification description                      |
|        Land.Class.Code        |                          Land classification code                         |
|        Total.Structures       |                 Total number of structures on the property                |
|          Total.Units          |                   Total number of units on the property                   |
|         Building.Value        | Revenue Dept. assessed value for structures contained within the property |
|           Land.Value          |    Revenue Dept. assessed value for land contained within the property    |
|        Land.Sale.Value        |                US dollar value for the land when last sold.               |
|         Land.Sale.Date        |                       Date that land was last sold.                       |
|        Total.Sale.Value       |        US dollar value for the land and building(s) when last sold.       |
|        Total.Sale.Date        |             Date that land and/or building(s) when last sold.             |
|             WC.ETJ            |                Corporate limits where property is located.                |
|         Billing.Class         |            Billing classifications for Revenue Department use.            |
|   APA.Ownership.Description   |         American Planning Association (APA) ownership description.        |
|    APA.Activity.Description   |                         APA activity description.                         |
|    APA.Function.Description   |                         APA function description.                         |
|      APA.Site.Description     |                           APA site description.                           |
| Total.Building.Square.Footage |                   Total square footage of the structure.                  |
|    Type.And.Use.Description   |                     Building use and type description                     |
|            Phy.City           |                      City where property is located.                      |
|          Shape.STArea         |                          Property structure area.                         |
|           Year.Built          |                          Year property was built.                         |

**Source: Town of Cary Dataset Schema**

Multiple Linear Regression
=======================================================================

summary {.sidebar}
-----------------------------------------------------------------------

### Summary

What maximizes the total sale value of a piece of property? After comparing all possible subsets and their criterion and accounting for collinearity, the model regressing the total sale value to the calculated acreage, total structures, total units and land sale value is our most accurate model.

However, the model violated all assumptions. Applying a log transform satisfies every assumption but normal distribution. You should note that this model might not produce the most accurate or precise results and should consider nonparametric methods and models.

Side-by-side comparisons are provided in the "Variance", "Normality" and "Leverage" tabs.

Column {data-width=500, .tabset}
-----------------------------------------------------------------------

### Research & Model Selection

```{r}
mlr_cols <- c(1, 4:8, 10, 18)
df_mlr <- df_w %>%
    dplyr::select(all_of(mlr_cols))
```

My goal for this section is to model what maximizes the total sale value of a plot of land from this dataset. Initially I wanted to include both numeric and categorical data in my model but I would run into some problems -- more on that later. Using the cleaned dataset, and all possible subsets, I picked out seven regressors and compared them and their criterion to each other: `Calculated.Acreage`, `Total.Structures`, `Total.Units`, `Building.Value`, `Land.Value`, `Land.Sale.Value`, and `Total.Building.Square.Footage`. The following shows these results.

```{r}
best_subsets <- regsubsets(Total.Sale.Value ~ ., data=df_mlr)
best_subsets_results <- summary(best_subsets)

attach(best_subsets_results)
table <- data.frame(outmat, adjr2, cp, bic)
colnames(table) <- c("Acreage", "Sructures", "Units", "Building", 
                    "Land", "Land Sale", "Sq. Footage", "AdjR2", "Cp", "BIC")
rownames(table) <- c(1, 2, 3, 4, 5, 6, 7)
knitr::kable(table)
detach(best_subsets_results)
```

As shown above, each criterion points to the fact that the full model is the most accurate model. This *seems* like a great fit to the data -- however, it's not. The model's variance inflation factor (VIF) and the data's scatterplot matrix, as shown to the right, proves that there is collinearity between the regressors.

```{r}
full_model <- lm(Total.Sale.Value ~ ., data=df_mlr)
vif(full_model)
```

This calls for a reduced model.

### Reduced Model & Diagnostics

Our new best model regresses `Total.Sale.Value` with `Calculated.Acreage`, `Total.Structures`, `Total.Units`, and `Land.Sale.Value`. The model summary and VIF is shown below.

```{r}
reduced_model <- lm(Total.Sale.Value ~ Calculated.Acreage + Total.Structures + Total.Units + Land.Sale.Value, 
                 data=df_mlr)
summary(reduced_model)
vif(reduced_model)
```

The calculated acreage, the land sale value, and the total number of structures and units have a direct correlation against the total sale value of a property. This model explains about 60.66% of the variance, as seen by the adjusted-$R^2$ value.

However, there's a problem: none of the assumptions for multiple linear regression are satisfied, and a log transform is necessary. The only problem that comes with this is that `Total.Units` cannot be used anymore since a large portion of the data contains zero.

### Final Model

The final model is as follows:

```{r}
final_model <- lm(log(Total.Sale.Value) ~ log(Calculated.Acreage) + log(Total.Structures) + 
                      log(Land.Sale.Value), data=df_mlr)
summary(final_model)
```

Looking at the graphs to the right (aside from collinearity), you can see a side-by-side comparison showing how the log transform has satisfied all assumptions but normality. With this in mind, this model might not produce the most accurate or precise results. Nonparametric methods should be considered when asking this question.

Column {data-width=500 .tabset}
-----------------------------------------------------------------------

### Collinearity

```{r}
temp_df <- df_mlr
colnames(temp_df) <- c("CA", "TS", "TU", "BV", "LV", "LSV", "TSV", "TBSF")
ggpairs(temp_df[1:10000, ]) + # i will NOT let R run 70000 data points 49 times.
    theme(axis.line=element_blank(), axis.text=element_blank(), axis.ticks=element_blank())
```

### Variance

```{r}
par(mfrow=c(2,1))
plot(reduced_model, which=1, pch=20, main="Full Model")
plot(final_model, which=1, pch=20, main="Log Model")
```

### Normality

```{r}
par(mfrow=c(2,1))
plot(reduced_model, which=2, pch=20, main="Full Model")
plot(final_model, which=2, pch=20, main="Log Model")
```

### Leverage

```{r}
par(mfrow=c(2,1))
plot(reduced_model, which=5, pch=20, main="Full Model")
plot(final_model, which=5, pch=20, main="Log Model")
```

Natural Cubic Splines
=======================================================================

### How Land Value affects Total Sale Value

```{r,  fig.width=10, fig.height=7}
#Creating dataframe for plot

ns_filtered <- df_w %>%
  filter(Land.Value < 250000, Total.Sale.Value < 900000) %>%
  select(Land.Value, Total.Sale.Value)

ns_df <- ns_filtered %>% sample_n(3000)

#Creating NS with different dfs
ns.1 <- lm(Total.Sale.Value ~ ns(Land.Value, df= 1), data = ns_df)
ns.2 <- lm(Total.Sale.Value ~ ns(Land.Value, df= 2), data = ns_df)
ns.3 <- lm(Total.Sale.Value ~ ns(Land.Value, df= 3), data = ns_df)
ns.4 <- lm(Total.Sale.Value ~ ns(Land.Value, df= 4), data = ns_df)
ns.5 <- lm(Total.Sale.Value ~ ns(Land.Value, df= 5), data = ns_df)

#Determining which df is best
SSE.1 <- sum(residuals(ns.1)^2)
SSE.2 <- sum(residuals(ns.2)^2)
SSE.3 <- sum(residuals(ns.3)^2)
SSE.4 <- sum(residuals(ns.4)^2)
SSE.5 <- sum(residuals(ns.5)^2)
SSE.1 <- c(SSE.1, SSE.2, SSE.3, SSE.4, SSE.5)
#From plotting separately, degree 3 seems best

#Plot

ggplot(data = ns_df, aes(x = Land.Value, y = Total.Sale.Value)) +
  geom_point(size = 0.9, color = "royalblue") +
  geom_smooth(method = "lm", formula = y ~ ns(x, df = 3), se = TRUE, 
              color = "brown4", size=2) +
  geom_vline(xintercept = attributes(ns(ns_df$Land.Value, df = 3))$knots, 
             linetype = "dashed", color = "black", size = 1) +
  ggtitle("Natural Cubic Spline on Land Value vs Total Sale Value") +
  labs(x = "Land Value ($)", y = "Total Sale Value ($)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 18, hjust = 0.5),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.position = "none")
```

As expected, the value of the land is directly correlated to to the Total Sale Value. The relationship does not appear to be exactly linear, but has a logarithmic curve.

Column {data-width=350}
-----------------------------------------------------------------------

### Chart B

```{r}

```

### Chart C

```{r}

```

Ridge Regression
=======================================================================

Naive Bayes'
=======================================================================

kNN Classification
=======================================================================

Logistic Regression
=======================================================================