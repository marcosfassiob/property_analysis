---
title: "AriqWork"
author: "Ariq Rashid"
date: "2023-11-06"
output: 
  pdf_document:
    highlight: haddock
keep_tex: no
number_sections: no
html_document:
  df_print: paged
geometry: margin = 0.5in
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
documentclass: article
urlcolor: blue
---

```{r setup, include=FALSE}
library(knitr) # I recommend doing this here
library(olsrr)
library(leaps)
library(ggplot2)
library(faraway)
library(GGally)
library(tidyverse)
library(glmnet)
library(ISLR2)
library(splines)
library(caret)
library(FNN)


# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, # Required
                      fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 7,
                      message = FALSE, # Turn off load messages
                      warning = FALSE # Turn off warnings
                      )
setwd("C:/Users/azras/OneDrive/Documents/School/VT/Fall 2023/Intermediate Data and ML - CMDA 4654/Project 1")
```

# Loading the Cleaned Data
```{r}
data <- data.frame(read.csv("cleaned_data.csv"))
View(data)
```

# Ridge Regression
```{r}
y <- data$Total.Sale.Value
x <- data.matrix(data[, c('Calculated.Acreage', 'Total.Structures', 'Total.Units', 'Building.Value','Land.Value','Land.Sale.Value')])
```

```{r}
ridge_model1 <- glmnet(x, y, alpha = 0)
cv_model1 <- cv.glmnet(x, y, alpha = 0)
best_lambda1 <- cv_model1$lambda.min
best_lambda1
plot(cv_model1)
```

```{r}
best_ridge_model <- glmnet(x, y, alpha = 0, lambda = best_lambda1)
coef(best_ridge_model)
```

```{r}
plot(ridge_model1, xvar = "lambda")
```

```{r}
#use fitted best model to make predictions
y_predicted <- predict(ridge_model1, s = best_lambda1, newx = x)

#find SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)

#find R-Squared
rsq <- 1 - sse/sst
rsq
```

# kNN Classification
```{r}
desired_columns <- c('Billing.Class','Total.Sale.Value','Calculated.Acreage',
                     'Total.Structures', 'Total.Units',
                     'Building.Value','Land.Value','Land.Sale.Value')
df <- data[, desired_columns]
View(df)
```

```{r}
index <- sample(1:nrow(df), round(nrow(df) * 0.7))
training_df <- df[index, ]
testing_df <- df[-index, ]

# Store the training/testing data features
train_features1 <- training_df[, 2:8]
test_features1 <- testing_df[, 2:8]

# Scale the features
train_features <- scale(train_features1)
test_features <- scale(test_features1)

# Store the actual labels (assuming Total.Sale.Value is a factor)
train_classes <- factor(training_df$Billing.Class)
test_classes <- factor(testing_df$Billing.Class)
```

```{r}
knn_classes <- knn(train = train_features, test = test_features,
cl = train_classes, k = 5)
knn_classes[1:nrow(test_features)]
```

```{r}

confusionMatrix(data = knn_classes, reference = test_classes)
#print(confusion_matrix)
```


# LOESS Fit --NOT DONE OR DECIDED--
# LOESS

```{r}
loess50 <- loess(y ~ x, data=data, span=.5)
smooth50 <- predict(loess50) 

loess75 <- loess(y ~ x, data=data, span=.75)
smooth75 <- predict(loess75) 

loess90 <- loess(y ~ x, data=data, span=.9)
smooth90 <- predict(loess90) 

#create scatterplot with each regression line overlaid
plot(data$x, data$y, pch=19, main='Loess Regression Models')
lines(smooth50, x=data$x, col='red')
lines(smooth75, x=df$x, col='purple')
lines(smooth90, x=df$x, col='blue')
legend('bottomright', legend=c('.5', '.75', '.9'),
        col=c('red', 'purple', 'blue'), pch=19, title='Smoothing Span')
```